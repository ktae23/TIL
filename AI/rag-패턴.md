# RAG 패턴 (Retrieval-Augmented Generation)

RAG는 대규모 언어 모델(LLM)의 성능을 향상시키기 위해 외부 지식 검색을 결합한 아키텍처 패턴입니다. LLM의 환각(hallucination) 문제를 완화하고, 최신 정보나 도메인 특화 지식을 활용할 수 있게 해줍니다.

## 목차

- [RAG란 무엇인가?](#rag란-무엇인가)
- [RAG가 필요한 이유](#rag가-필요한-이유)
- [RAG의 기본 구조](#rag의-기본-구조)
- [RAG의 핵심 구성 요소](#rag의-핵심-구성-요소)
- [RAG의 작동 방식](#rag의-작동-방식)
- [RAG의 장단점](#rag의-장단점)
- [실제 활용 사례](#실제-활용-사례)

---

## RAG란 무엇인가?

**RAG (Retrieval-Augmented Generation)**는 2020년 Meta AI가 제안한 자연어 처리 아키텍처로, 다음 두 가지를 결합합니다:

1. **Retrieval (검색)**: 외부 데이터베이스나 문서에서 관련 정보를 검색
2. **Generation (생성)**: 검색된 정보를 기반으로 LLM이 응답 생성

기존 LLM은 학습 데이터에만 의존하지만, RAG는 실시간으로 외부 지식을 참조하여 더 정확하고 최신의 답변을 제공합니다.

---

## RAG가 필요한 이유

### 1. LLM의 근본적인 한계

**환각 현상 (Hallucination)**
- LLM은 그럴듯하지만 사실이 아닌 정보를 생성할 수 있습니다
- 학습 데이터에 없는 내용을 추측하여 만들어냅니다

**지식의 시간적 한계**
- 모델은 학습 시점까지의 데이터만 알고 있습니다
- 최신 정보나 실시간 데이터에 접근할 수 없습니다

**도메인 지식 부족**
- 특정 기업이나 조직의 내부 문서, 전문 지식은 학습되지 않았습니다
- 일반적인 지식만 제공할 수 있습니다

### 2. RAG의 해결책

RAG는 이러한 문제를 **외부 지식 소스를 실시간으로 참조**함으로써 해결합니다:

- 검색된 실제 문서를 기반으로 답변 → 환각 감소
- 최신 문서를 인덱싱하여 검색 → 최신 정보 제공
- 회사 내부 문서, 매뉴얼 등을 지식 베이스로 활용 → 도메인 특화

---

## RAG의 기본 구조

```
[사용자 질문]
       ↓
[질문 임베딩 벡터화]
       ↓
[벡터 DB에서 유사 문서 검색] ← [지식 베이스 (문서들)]
       ↓
[검색된 문서 + 원래 질문]
       ↓
[LLM이 컨텍스트 기반 응답 생성]
       ↓
[최종 답변]
```

---

## RAG의 핵심 구성 요소

### 1. 지식 베이스 (Knowledge Base)

외부 정보의 원천이 되는 문서 저장소입니다.

- **형태**: PDF, 웹페이지, 데이터베이스, API 응답 등
- **예시**:
  - 회사 내부 문서, 기술 문서
  - 뉴스 기사, 위키피디아
  - 제품 매뉴얼, FAQ

### 2. 임베딩 모델 (Embedding Model)

텍스트를 벡터로 변환하여 의미적 유사도를 계산할 수 있게 합니다.

- **역할**: 문서와 질문을 같은 벡터 공간에 표현
- **대표 모델**:
  - OpenAI의 `text-embedding-ada-002`
  - Sentence Transformers
  - Cohere Embed

**임베딩 과정**:
```
"RAG란 무엇인가?"
  ↓ 임베딩
[0.234, -0.521, 0.892, ..., 0.123]  (벡터)
```

### 3. 벡터 데이터베이스 (Vector Database)

임베딩된 문서들을 저장하고, 질문과 유사한 문서를 빠르게 검색합니다.

- **대표적인 벡터 DB**:
  - Pinecone
  - Weaviate
  - Chroma
  - FAISS (Facebook AI Similarity Search)

- **검색 방식**: 코사인 유사도(Cosine Similarity)를 사용하여 가장 관련성 높은 문서 찾기

### 4. 리트리버 (Retriever)

사용자 질문과 관련된 문서를 벡터 DB에서 검색하는 컴포넌트입니다.

- **검색 전략**:
  - Top-K 검색: 가장 유사한 상위 K개 문서 반환
  - Threshold 기반: 유사도가 일정 수준 이상인 문서만 반환

### 5. 생성 모델 (Generator - LLM)

검색된 문서를 컨텍스트로 받아 최종 답변을 생성합니다.

- **대표 모델**:
  - GPT-4, GPT-3.5
  - Claude
  - LLaMA
  - PaLM

---

## RAG의 작동 방식

### 단계별 프로세스

**1단계: 지식 베이스 구축 (사전 작업)**

```
원본 문서들
    ↓ 청크 분할 (Chunking)
작은 단위 텍스트 조각들
    ↓ 임베딩
벡터들
    ↓ 저장
벡터 데이터베이스
```

**청크 분할 예시**:
```
원본: 5000자 문서
  ↓
청크1: 500자 (오버랩 50자)
청크2: 500자 (오버랩 50자)
청크3: 500자 (오버랩 50자)
...
```

**2단계: 질문 처리 (실시간)**

```
사용자: "RAG의 장점은 무엇인가요?"
    ↓ 임베딩
질문 벡터 [0.123, 0.456, ...]
    ↓ 벡터 DB 검색 (유사도 계산)
관련 문서 청크 3개 검색
    ↓ 프롬프트 구성
"다음 문서를 참고하여 답변하세요:
[검색된 문서1]
[검색된 문서2]
[검색된 문서3]

질문: RAG의 장점은 무엇인가요?"
    ↓ LLM 생성
최종 답변
```

### 프롬프트 구성 예시

```
You are a helpful assistant. Answer the question based on the context below.

Context:
"""
[검색된 문서1 내용]
[검색된 문서2 내용]
[검색된 문서3 내용]
"""

Question: RAG의 장점은 무엇인가요?

Answer: [LLM이 생성]
```

---

## RAG의 장단점

### 장점

| 장점 | 설명 |
|------|------|
| **환각 감소** | 실제 문서 기반 답변으로 신뢰성 향상 |
| **최신 정보** | 지식 베이스 업데이트만으로 최신 정보 반영 가능 |
| **도메인 특화** | 특정 조직/분야의 지식을 쉽게 통합 |
| **비용 효율적** | 전체 모델 재학습 없이 지식 확장 가능 |
| **출처 추적** | 답변의 근거가 된 문서를 제시 가능 |
| **프라이버시** | 민감한 데이터를 모델 학습 없이 활용 |

### 단점

| 단점 | 설명 |
|------|------|
| **검색 품질 의존** | 관련 문서를 찾지 못하면 답변 품질 저하 |
| **지연 시간** | 검색 과정으로 인한 응답 시간 증가 |
| **컨텍스트 길이 제한** | LLM의 토큰 제한으로 많은 문서 참조 불가 |
| **인프라 복잡도** | 벡터 DB, 임베딩 모델 등 추가 시스템 필요 |
| **청킹 전략** | 문서 분할 방식에 따라 성능 크게 달라짐 |

---

## 실제 활용 사례

### 1. 고객 지원 챗봇

**시나리오**: 제품 매뉴얼 기반 고객 문의 응답

- **지식 베이스**: 제품 매뉴얼, FAQ, 이전 고객 문의 기록
- **효과**: 정확한 제품 정보 제공, 고객 만족도 향상

### 2. 기업 내부 지식 검색

**시나리오**: 직원들이 사내 문서를 자연어로 검색

- **지식 베이스**: 회의록, 정책 문서, 프로젝트 문서
- **효과**: 빠른 정보 접근, 업무 효율성 증대

### 3. 법률/의료 자문

**시나리오**: 전문 지식 기반 초안 작성 지원

- **지식 베이스**: 법률 판례, 의학 논문, 가이드라인
- **효과**: 전문가의 의사결정 지원, 참고 자료 빠른 검색

### 4. 코드 문서화 도우미

**시나리오**: 코드베이스 질의응답

- **지식 베이스**: 코드, API 문서, 커밋 히스토리
- **효과**: 신입 개발자 온보딩, 코드 이해도 향상

---

## 참고 자료

- [RAG 원논문: "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" (Lewis et al., 2020)](https://arxiv.org/abs/2005.11401)
- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)

---

*마지막 업데이트: 2025년 12월*
